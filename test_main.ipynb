{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "544740c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import warnings\n",
    "\n",
    "import hydra\n",
    "import hydra.core.hydra_config\n",
    "import omegaconf\n",
    "\n",
    "import pathlib\n",
    "import typing\n",
    "\n",
    "\n",
    "#Register additional resolver for log path\n",
    "omegaconf.OmegaConf.register_new_resolver(\"list_to_string\", lambda o: functools.reduce(lambda acc, x: acc+\", \"+x.replace(\"\\\"\",\"\").replace(\"/\",\" \"), o, \"\")[2:])\n",
    "omegaconf.OmegaConf.register_new_resolver(\"eval\", lambda c: eval(c))\n",
    "\n",
    "import pytorch_lightning\n",
    "import pytorch_lightning.accelerators\n",
    "import pytorch_lightning.callbacks\n",
    "import pytorch_lightning.loggers\n",
    "import pytorch_lightning.utilities\n",
    "\n",
    "import torch\n",
    "import torch.utils.tensorboard\n",
    "import torch.version\n",
    "\n",
    "from mnist_datamodule import MNISTDataModule\n",
    "from ellipses_datamodule import EllipsesDataModule\n",
    "from learned_filter_model import LearnedFilterModel\n",
    "from analytic_filter_model import AnalyticFilterModel\n",
    "from learned_svd_model import LearnedSVDModel\n",
    "\n",
    "\n",
    "#Custom version of pytorch lightnings TensorBoardLogger, to allow manipulation of internal logging settings\n",
    "class CustomTensorBoardLogger(pytorch_lightning.loggers.TensorBoardLogger):\n",
    "    #Disables logging of epoch\n",
    "    @pytorch_lightning.utilities.rank_zero_only\n",
    "    def log_metrics(self, metrics: dict[str, typing.Union[torch.Tensor, float]], step: int) -> None:\n",
    "        metrics.pop(\"epoch\", None)\n",
    "        return super().log_metrics(metrics, step)\n",
    "    \n",
    "    #Disables creation of hparams.yaml\n",
    "    @pytorch_lightning.utilities.rank_zero_only\n",
    "    def save(self) -> None:\n",
    "        dir_path = self.log_dir\n",
    "        if not os.path.isdir(dir_path):\n",
    "            dir_path = self.save_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "282fda8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@hydra.main(config_path=\"configs\", config_name=\"default\", version_base=None)\n",
    "def main(config: omegaconf.DictConfig) -> None:\n",
    "    #Setup logging\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.captureWarnings(True)\n",
    "    logging.getLogger(\"pytorch_lightning\").handlers.append(logger.root.handlers[1]) #Route pytorch lightning logging to hydra logger\n",
    "    for old_log in os.listdir(hydra.core.hydra_config.HydraConfig.get().runtime.output_dir):\n",
    "        if old_log.startswith(\"events.out.tfevents\"):\n",
    "            os.remove(os.path.join(hydra.core.hydra_config.HydraConfig.get().runtime.output_dir, old_log))\n",
    "\n",
    "    #Set num_workers to available CPU count\n",
    "    if config.num_workers == -1:\n",
    "        config.num_workers = os.cpu_count()\n",
    "    \n",
    "    #Initialize determinism\n",
    "    if config.deterministic:\n",
    "        pytorch_lightning.seed_everything(config.seed, workers=True)\n",
    "\n",
    "    #Create model and load data\n",
    "    if config.model.name == \"analytic\":\n",
    "        modelClass = AnalyticFilterModel\n",
    "    elif config.model.name == \"learned\":\n",
    "        modelClass = LearnedFilterModel\n",
    "    elif config.model.name == \"svd\":\n",
    "        modelClass = LearnedSVDModel\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    if config.checkpoint != None:\n",
    "        model = modelClass.load_from_checkpoint(os.path.abspath(os.path.join(\"../../\" if hydra.core.hydra_config.HydraConfig.get().mode == hydra.types.RunMode.MULTIRUN else \"../\", config.checkpoint)), config=config)\n",
    "    else:\n",
    "        model = modelClass(config)\n",
    "    if config.dataset.name == \"MNIST\":\n",
    "        datamodule = MNISTDataModule(config)\n",
    "    elif config.dataset.name == \"ellipses\":\n",
    "        datamodule = EllipsesDataModule(config)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "    datamodule = EllipsesDataModule(config)\n",
    "    return datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5828476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [--help] [--hydra-help] [--version]\n",
      "                             [--cfg {job,hydra,all}] [--resolve]\n",
      "                             [--package PACKAGE] [--run] [--multirun]\n",
      "                             [--shell-completion] [--config-path CONFIG_PATH]\n",
      "                             [--config-name CONFIG_NAME]\n",
      "                             [--config-dir CONFIG_DIR]\n",
      "                             [--experimental-rerun EXPERIMENTAL_RERUN]\n",
      "                             [--info [{all,config,defaults,defaults-tree,plugins,searchpath}]]\n",
      "                             [overrides ...]\n",
      "ipykernel_launcher.py: error: argument --shell-completion/-sc: ignored explicit argument '9002'\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1851\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1851\u001b[0m     namespace, args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_known_args(args, namespace)\n\u001b[0;32m   1852\u001b[0m \u001b[39mexcept\u001b[39;00m ArgumentError:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2060\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[1;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \u001b[39m# consume the next optional and any arguments for it\u001b[39;00m\n\u001b[1;32m-> 2060\u001b[0m     start_index \u001b[39m=\u001b[39m consume_optional(start_index)\n\u001b[0;32m   2062\u001b[0m \u001b[39m# consume any positionals following the last Optional\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1982\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_optional\u001b[1;34m(start_index)\u001b[0m\n\u001b[0;32m   1981\u001b[0m         msg \u001b[39m=\u001b[39m _(\u001b[39m'\u001b[39m\u001b[39mignored explicit argument \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1982\u001b[0m         \u001b[39mraise\u001b[39;00m ArgumentError(action, msg \u001b[39m%\u001b[39m explicit_arg)\n\u001b[0;32m   1984\u001b[0m \u001b[39m# if there is no explicit argument, try to match the\u001b[39;00m\n\u001b[0;32m   1985\u001b[0m \u001b[39m# optional's string arguments with the following strings\u001b[39;00m\n\u001b[0;32m   1986\u001b[0m \u001b[39m# if successful, exit the loop\u001b[39;00m\n\u001b[0;32m   1987\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mArgumentError\u001b[0m: argument --shell-completion/-sc: ignored explicit argument '9002'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn [5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m datamodule \u001b[39m=\u001b[39m main()\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\hydra\\main.py:82\u001b[0m, in \u001b[0;36mmain.<locals>.main_decorator.<locals>.decorated_main\u001b[1;34m(cfg_passthrough)\u001b[0m\n\u001b[0;32m     81\u001b[0m args_parser \u001b[39m=\u001b[39m get_args_parser()\n\u001b[1;32m---> 82\u001b[0m args \u001b[39m=\u001b[39m args_parser\u001b[39m.\u001b[39;49mparse_args()\n\u001b[0;32m     83\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mexperimental_rerun \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1818\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1817\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_args\u001b[39m(\u001b[39mself\u001b[39m, args\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, namespace\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1818\u001b[0m     args, argv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_known_args(args, namespace)\n\u001b[0;32m   1819\u001b[0m     \u001b[39mif\u001b[39;00m argv:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:1854\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1853\u001b[0m         err \u001b[39m=\u001b[39m _sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m1\u001b[39m]\n\u001b[1;32m-> 1854\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror(\u001b[39mstr\u001b[39;49m(err))\n\u001b[0;32m   1855\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2575\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2574\u001b[0m args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mprog\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprog, \u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m: message}\n\u001b[1;32m-> 2575\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexit(\u001b[39m2\u001b[39;49m, _(\u001b[39m'\u001b[39;49m\u001b[39m%(prog)s\u001b[39;49;00m\u001b[39m: error: \u001b[39;49m\u001b[39m%(message)s\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m) \u001b[39m%\u001b[39;49m args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\argparse.py:2562\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2561\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_message(message, _sys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m-> 2562\u001b[0m _sys\u001b[39m.\u001b[39;49mexit(status)\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\IPython\\core\\interactiveshell.py:1987\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   1984\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[0;32m   1985\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1986\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> 1987\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[0;32m   1988\u001b[0m                                                      value))\n\u001b[0;32m   1989\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1990\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1991\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[0;32m   1992\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\IPython\\core\\ultratb.py:579\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[0;32m    572\u001b[0m     \u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \n\u001b[0;32m    574\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\IPython\\core\\ultratb.py:446\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    443\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[0;32m    444\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    445\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 446\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m    447\u001b[0m             etype, evalue, (etb, chained_exc_ids),\n\u001b[0;32m    448\u001b[0m             chained_exceptions_tb_offset, context)\n\u001b[0;32m    449\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[0;32m    450\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[0;32m    452\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\IPython\\core\\ultratb.py:1112\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m tb\n\u001b[1;32m-> 1112\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1113\u001b[0m     \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\IPython\\core\\ultratb.py:1006\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1003\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[0;32m   1005\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1006\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1007\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1008\u001b[0m     )\n\u001b[0;32m   1009\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1010\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\IPython\\core\\ultratb.py:859\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[0;32m    851\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    852\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    856\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[0;32m    857\u001b[0m ):\n\u001b[0;32m    858\u001b[0m     \u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m    860\u001b[0m                                                            tb_offset)\n\u001b[0;32m    862\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m    863\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\IPython\\core\\ultratb.py:793\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[0;32m    791\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(etype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[0;32m    792\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 793\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[0;32m    794\u001b[0m )\n\u001b[0;32m    796\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[0;32m    797\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\IPython\\core\\ultratb.py:848\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    842\u001b[0m     formatter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    843\u001b[0m options \u001b[39m=\u001b[39m stack_data\u001b[39m.\u001b[39mOptions(\n\u001b[0;32m    844\u001b[0m     before\u001b[39m=\u001b[39mbefore,\n\u001b[0;32m    845\u001b[0m     after\u001b[39m=\u001b[39mafter,\n\u001b[0;32m    846\u001b[0m     pygments_formatter\u001b[39m=\u001b[39mformatter,\n\u001b[0;32m    847\u001b[0m )\n\u001b[1;32m--> 848\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(stack_data\u001b[39m.\u001b[39;49mFrameInfo\u001b[39m.\u001b[39;49mstack_data(etb, options\u001b[39m=\u001b[39;49moptions))[tb_offset:]\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\stack_data\\core.py:578\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[1;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    563\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack_data\u001b[39m(\n\u001b[0;32m    564\u001b[0m         \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    568\u001b[0m         collapse_repeated_frames: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    569\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[\u001b[39m'\u001b[39m\u001b[39mFrameInfo\u001b[39m\u001b[39m'\u001b[39m, RepeatedFrames]]:\n\u001b[0;32m    570\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[39m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[39m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[39m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m     stack \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(iter_stack(frame_or_tb))\n\u001b[0;32m    580\u001b[0m     \u001b[39m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[0;32m    581\u001b[0m     \u001b[39m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[0;32m    582\u001b[0m     \u001b[39m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[0;32m    583\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\stack_data\\utils.py:98\u001b[0m, in \u001b[0;36miter_stack\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mwhile\u001b[39;00m frame_or_tb:\n\u001b[0;32m     97\u001b[0m     \u001b[39myield\u001b[39;00m frame_or_tb\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mif\u001b[39;00m is_frame(frame_or_tb):\n\u001b[0;32m     99\u001b[0m         frame_or_tb \u001b[39m=\u001b[39m frame_or_tb\u001b[39m.\u001b[39mf_back\n\u001b[0;32m    100\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\stack_data\\utils.py:91\u001b[0m, in \u001b[0;36mis_frame\u001b[1;34m(frame_or_tb)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m---> 91\u001b[0m     assert_(\u001b[39misinstance\u001b[39;49m(frame_or_tb, (types\u001b[39m.\u001b[39;49mFrameType, types\u001b[39m.\u001b[39;49mTracebackType)))\n\u001b[0;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(frame_or_tb, (types\u001b[39m.\u001b[39mFrameType,))\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\stack_data\\utils.py:172\u001b[0m, in \u001b[0;36massert_\u001b[1;34m(condition, error)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(error, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    171\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mAssertionError\u001b[39;00m(error)\n\u001b[1;32m--> 172\u001b[0m \u001b[39mraise\u001b[39;00m error\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datamodule = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14d96261",
   "metadata": {},
   "outputs": [],
   "source": [
    "@hydra.main(config_path=\"configs\", config_name=\"default\", version_base=None)\n",
    "def main(config: omegaconf.DictConfig) -> None:\n",
    "    #Setup logging\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.captureWarnings(True)\n",
    "    logging.getLogger(\"pytorch_lightning\").handlers.append(logger.root.handlers[1]) #Route pytorch lightning logging to hydra logger\n",
    "    for old_log in os.listdir(hydra.core.hydra_config.HydraConfig.get().runtime.output_dir):\n",
    "        if old_log.startswith(\"events.out.tfevents\"):\n",
    "            os.remove(os.path.join(hydra.core.hydra_config.HydraConfig.get().runtime.output_dir, old_log))\n",
    "\n",
    "    #Set num_workers to available CPU count\n",
    "    if config['num_workers'] == -1:\n",
    "        config['num_workers'] = os.cpu_count()\n",
    "    \n",
    "    #Initialize determinism\n",
    "    if config['deterministic']:\n",
    "        pytorch_lightning.seed_everything(config.seed, workers=True)\n",
    "\n",
    "    #Create model and load data\n",
    "    if config['model']['name'] == \"analytic\":\n",
    "        modelClass = AnalyticFilterModel\n",
    "    elif config['model']['name'] == \"learned\":\n",
    "        modelClass = LearnedFilterModel\n",
    "    elif config['model']['name'] == \"svd\":\n",
    "        modelClass = LearnedSVDModel\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    if config['checkpoint'] != None:\n",
    "        model = modelClass.load_from_checkpoint(os.path.abspath(os.path.join(\"../../\" if hydra.core.hydra_config.HydraConfig.get().mode == hydra.types.RunMode.MULTIRUN else \"../\", config.checkpoint)), config=config)\n",
    "    else:\n",
    "        model = modelClass(config)\n",
    "    if config['dataset']['name'] == \"MNIST\":\n",
    "        datamodule = MNISTDataModule(config)\n",
    "    elif config['dataset']['name'] == \"ellipses\":\n",
    "        datamodule = EllipsesDataModule(config)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "    # datamodule = EllipsesDataModule(config)\n",
    "    return datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d3e9a56",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m datamodule \u001b[39m=\u001b[39m main(config)\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\hydra\\main.py:79\u001b[0m, in \u001b[0;36mmain.<locals>.main_decorator.<locals>.decorated_main\u001b[1;34m(cfg_passthrough)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(task_function)\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorated_main\u001b[39m(cfg_passthrough: Optional[DictConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m cfg_passthrough \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m         \u001b[39mreturn\u001b[39;00m task_function(cfg_passthrough)\n\u001b[0;32m     80\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m         args_parser \u001b[39m=\u001b[39m get_args_parser()\n",
      "Cell \u001b[1;32mIn [31], line 6\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m      4\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[0;32m      5\u001b[0m logging\u001b[39m.\u001b[39mcaptureWarnings(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m\"\u001b[39m\u001b[39mpytorch_lightning\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mhandlers\u001b[39m.\u001b[39mappend(logger\u001b[39m.\u001b[39;49mroot\u001b[39m.\u001b[39;49mhandlers[\u001b[39m1\u001b[39;49m]) \u001b[39m#Route pytorch lightning logging to hydra logger\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m old_log \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(hydra\u001b[39m.\u001b[39mcore\u001b[39m.\u001b[39mhydra_config\u001b[39m.\u001b[39mHydraConfig\u001b[39m.\u001b[39mget()\u001b[39m.\u001b[39mruntime\u001b[39m.\u001b[39moutput_dir):\n\u001b[0;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m old_log\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mevents.out.tfevents\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "datamodule = main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d526000",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'dataset': {\n",
    "        'name': 'ellipses'\n",
    "    },\n",
    "    'num_workers': 1,\n",
    "    'out_dir': '/LearnedRadonFilters',\n",
    "    'deterministic': True,\n",
    "    'seed': 1234567,\n",
    "    'device': \"cuda\",\n",
    "    'num_workers': 1,\n",
    "    'defaults':{\n",
    "        'model': 'analytic',\n",
    "        'dataset': 'ellipses'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cafc3e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ellipses'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['dataset']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd80da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['something new'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73e6cc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'name': 'ellipses'},\n",
       " 'num_workers': 1,\n",
       " 'out_dir': '/LearnedRadonFilters',\n",
       " 'deterministic': True,\n",
       " 'seed': 1234567,\n",
       " 'device': 'cuda',\n",
       " 'defaults': {'model': 'analytic', 'dataset': 'ellipses'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1429eef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52190aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330d8f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo le variabili\n"
     ]
    }
   ],
   "source": [
    "# Saving the objects:\n",
    "print(\"Salvo le variabili\")\n",
    "with open('test_datamodule.pkl', 'wb') as f:\n",
    "    pickle.dump(config, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aced4566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config does not exist\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del config\n",
    "except:\n",
    "    print(\"config does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a062c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config does not exist\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del config\n",
    "except:\n",
    "    print(\"config does not exist\")\n",
    "\n",
    "with open('./LearnedRadonFilters/_debug/test_datamodule.pkl', 'rb') as f:\n",
    "    config = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b82c2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ellipses_datamodule.EllipsesDataModule at 0x17f85c53b80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "606fd71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danil\\Desktop\\oct2022\\test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "this_dir = os.getcwd()\n",
    "print(this_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3533cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ellipses_datamodule.EllipsesDataModule object at 0x0000017F85C53B80>\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31ee0abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "print(type(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3148e1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed01365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyright: reportPrivateImportUsage=false, reportGeneralTypeIssues=false\n",
    "import functools\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import warnings\n",
    "\n",
    "import hydra\n",
    "import hydra.core.hydra_config\n",
    "import omegaconf\n",
    "\n",
    "import pathlib\n",
    "import typing\n",
    "\n",
    "\n",
    "#Register additional resolver for log path\n",
    "omegaconf.OmegaConf.register_new_resolver(\"list_to_string\", lambda o: functools.reduce(lambda acc, x: acc+\", \"+x.replace(\"\\\"\",\"\").replace(\"/\",\" \"), o, \"\")[2:])\n",
    "omegaconf.OmegaConf.register_new_resolver(\"eval\", lambda c: eval(c))\n",
    "\n",
    "import pytorch_lightning\n",
    "import pytorch_lightning.accelerators\n",
    "import pytorch_lightning.callbacks\n",
    "import pytorch_lightning.loggers\n",
    "import pytorch_lightning.utilities\n",
    "\n",
    "import torch\n",
    "import torch.utils.tensorboard\n",
    "import torch.version\n",
    "\n",
    "from mnist_datamodule import MNISTDataModule\n",
    "from ellipses_datamodule import EllipsesDataModule\n",
    "from learned_filter_model import LearnedFilterModel\n",
    "from analytic_filter_model import AnalyticFilterModel\n",
    "from learned_svd_model import LearnedSVDModel\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "#Custom version of pytorch lightnings TensorBoardLogger, to allow manipulation of internal logging settings\n",
    "class CustomTensorBoardLogger(pytorch_lightning.loggers.TensorBoardLogger):\n",
    "    #Disables logging of epoch\n",
    "    @pytorch_lightning.utilities.rank_zero_only\n",
    "    def log_metrics(self, metrics: dict[str, typing.Union[torch.Tensor, float]], step: int) -> None:\n",
    "        metrics.pop(\"epoch\", None)\n",
    "        return super().log_metrics(metrics, step)\n",
    "    \n",
    "    #Disables creation of hparams.yaml\n",
    "    @pytorch_lightning.utilities.rank_zero_only\n",
    "    def save(self) -> None:\n",
    "        dir_path = self.log_dir\n",
    "        if not os.path.isdir(dir_path):\n",
    "            dir_path = self.save_dir\n",
    "\n",
    "\n",
    "with open('./LearnedRadonFilters/_debug/test_datamodule_1.pkl', 'rb') as f:\n",
    "    datamodule = pickle.load(f)\n",
    "with open('./LearnedRadonFilters/_debug/test_config_1.pkl', 'rb') as f:\n",
    "    config = pickle.load(f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "68da1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ecfcf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./LearnedRadonFilters/_debug/test_datamodule.pkl', 'rb') as f:\n",
    "    datamodule = pickle.load(f)\n",
    "with open('./LearnedRadonFilters/_debug/test_config.pkl', 'rb') as f:\n",
    "    config = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20768453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234567\n"
     ]
    }
   ],
   "source": [
    "#Initialize determinism\n",
    "if config.deterministic:\n",
    "    pytorch_lightning.seed_everything(config.seed, workers=True)\n",
    "\n",
    "#Create model and load data\n",
    "if config.model.name == \"analytic\":\n",
    "    modelClass = AnalyticFilterModel\n",
    "elif config.model.name == \"learned\":\n",
    "    modelClass = LearnedFilterModel\n",
    "elif config.model.name == \"svd\":\n",
    "    modelClass = LearnedSVDModel\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "if config.checkpoint != None:\n",
    "    model = modelClass.load_from_checkpoint(os.path.abspath(os.path.join(\"../../\" if hydra.core.hydra_config.HydraConfig.get().mode == hydra.types.RunMode.MULTIRUN else \"../\", config.checkpoint)), config=config)\n",
    "else:\n",
    "    model = modelClass(config)\n",
    "if config.dataset.name == \"MNIST\":\n",
    "    datamodule = MNISTDataModule(config)\n",
    "elif config.dataset.name == \"ellipses\":\n",
    "    datamodule = EllipsesDataModule(config)\n",
    "else:\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f44b1586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ellipses_datamodule.EllipsesDataModule at 0x17fa6def1c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37b576f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datamodule.train_dataloader())\n",
    "\n",
    "for X in iter(datamodule.train_dataloader()):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7faba8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fcaac99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(X[0].shape)\n",
    "\n",
    "for cont in range(len(X[0])):\n",
    "    plt.imshow((X[0][cont]).view(256,256))\n",
    "    plt.savefig(f\"mygraph__1_{cont:02d}.png\")\n",
    "    if cont>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a78a29e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import atan, cos, sin, tan\n",
    "import typing\n",
    "\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision.transforms\n",
    "import torchvision.transforms.functional\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "import matplotlib.patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class _EllipsesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_count: int, img_size: int, ellipses_count: int, ellipses_size: float, ellipses_size_min: float=1, transform: typing.Union[typing.Callable[[torch.Tensor],torch.Tensor], None]=None, number_ellipses_poisson=False):\n",
    "        self.img_count = img_count\n",
    "        self.img_size = img_size\n",
    "        if number_ellipses_poisson == True:\n",
    "            self.ellipses_count = torch.poisson(torch.full((img_count,), ellipses_count).to(torch.float32)).to(torch.int32)\n",
    "        else:\n",
    "            self.ellipses_count = (torch.full((img_count,), ellipses_count).to(torch.float32)).to(torch.int32)\n",
    "        real_ellipses_count = self.ellipses_count.sum()\n",
    "        self.ellipse_width_aa = torch.rand((real_ellipses_count,))*max(0.0, ellipses_size-ellipses_size_min)+ellipses_size_min\n",
    "        self.ellipse_height_aa = torch.rand((real_ellipses_count,))*max(0.0, ellipses_size-ellipses_size_min)+ellipses_size_min\n",
    "        self.ellipse_x_raw = torch.rand((real_ellipses_count,))\n",
    "        self.ellipse_y_raw = torch.rand((real_ellipses_count,))\n",
    "        self.ellipse_angle = torch.rand((real_ellipses_count,))*360.0\n",
    "        self.ellipse_alpha = torch.rand((real_ellipses_count,))*0.9+0.1\n",
    "\n",
    "        #self.ellipses_count = torch.ones((img_count,), dtype=torch.int32)\n",
    "        #self.ellipse_width_aa = torch.full((img_count,), 1.0)#ellipses_size)\n",
    "        #self.ellipse_height_aa = torch.full((img_count,), 1.0)#ellipses_size)\n",
    "        #self.ellipse_x_raw = torch.full((img_count,), 0.5)\n",
    "        #self.ellipse_y_raw = torch.full((img_count,), 0.5)\n",
    "        #self.ellipse_angle = torch.zeros((img_count,))\n",
    "        #self.ellipse_alpha = torch.ones((img_count,))\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.channel_selection_mode = \"alpha\"\n",
    "        if self[0][0].sum() == self.img_size*self.img_size:\n",
    "            self.channel_selection_mode = \"noalpha\"\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.img_count\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, int]:\n",
    "        fig = plt.figure(figsize=(self.img_size,self.img_size), dpi=1)\n",
    "        ax = fig.add_axes([0.0,0.0,1.0,1.0])\n",
    "        ellipse_func = lambda w, h, a, t: (w/2.0*cos(t)*cos(a)-h/2.0*sin(t)*sin(a), w/2.0*cos(t)*sin(a)+h/2.0*sin(t)*cos(a))\n",
    "        prev_ellipses_count = self.ellipses_count[:idx].sum()\n",
    "        for i in range(self.ellipses_count[idx]):\n",
    "            e_idx = prev_ellipses_count+i\n",
    "            args = (self.ellipse_width_aa[e_idx].item(), self.ellipse_height_aa[e_idx].item(), self.ellipse_angle[e_idx].item()/180.0*torch.pi)\n",
    "            if self.ellipse_angle[idx] == 0.0:\n",
    "                ellipse_width = self.ellipse_width_aa[e_idx]\n",
    "                ellipse_height = self.ellipse_height_aa[e_idx]\n",
    "            else:\n",
    "                t = atan(-self.ellipse_height_aa[e_idx].item()*tan(self.ellipse_angle[e_idx].item()/180.0*torch.pi)/self.ellipse_width_aa[e_idx].item())\n",
    "                ellipse_width = max(ellipse_func(*args, t)[0], ellipse_func(*args, t+torch.pi)[0])-min(ellipse_func(*args, t)[0], ellipse_func(*args, t+torch.pi)[0])\n",
    "                t = atan(self.ellipse_height_aa[e_idx].item()/(tan(self.ellipse_angle[e_idx].item()/180.0*torch.pi)*self.ellipse_width_aa[e_idx].item()))\n",
    "                ellipse_height = max(ellipse_func(*args, t)[1], ellipse_func(*args, t+torch.pi)[1])-min(ellipse_func(*args, t)[1], ellipse_func(*args, t+torch.pi)[1])\n",
    "            ellipse_x = ellipse_width/2.0+self.ellipse_x_raw[e_idx].item()*(self.img_size-ellipse_width)\n",
    "            ellipse_y = ellipse_height/2.0+self.ellipse_y_raw[e_idx].item()*(self.img_size-ellipse_height)\n",
    "            ellipse = matplotlib.patches.Ellipse(xy=[ellipse_x, ellipse_y], width=self.ellipse_width_aa[e_idx].item(), height=self.ellipse_height_aa[e_idx].item(), angle=self.ellipse_angle[e_idx].item())\n",
    "            ax.add_artist(ellipse)\n",
    "            ellipse.set_clip_box(ax.bbox)\n",
    "            ellipse.set_alpha(self.ellipse_alpha[e_idx].item())\n",
    "            ellipse.set_facecolor(\"black\")\n",
    "            ellipse.set_edgecolor(None)\n",
    "            ellipse.set_antialiased(False)\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_xlim(0.0, self.img_size)\n",
    "        ax.set_ylim(0.0, self.img_size)\n",
    "        fig.add_axes(ax)\n",
    "        fig.canvas.draw()\n",
    "        img = torch.from_numpy(np.frombuffer(fig.canvas.tostring_argb(), dtype=np.uint8).copy())\n",
    "        if self.channel_selection_mode == \"noalpha\":\n",
    "            img = 1.0-torch.swapaxes(img.reshape(self.img_size,self.img_size,4), 0, 2).to(torch.float32)[3:4]/255.0\n",
    "        elif self.channel_selection_mode == \"alpha\":\n",
    "            img = torch.swapaxes(img.reshape(self.img_size,self.img_size,4), 0, 2).to(torch.float32)[0:1]/255.0\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "        plt.close()\n",
    "        if self.transform != None:\n",
    "            img = self.transform(img)\n",
    "        return img, 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6198f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.dataset.ellipse_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3333989b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.dataset.ellipse_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97a32bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_img_count = 1#640*32\n",
    "my_image_size = 256#256\n",
    "my_ellipses_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65fd897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "print(config.training_batch_count)\n",
    "print(config.training_batch_size)\n",
    "print(config.dataset.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a859feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'name': 'analytic'}, 'dataset': {'name': 'ellipses', 'img_size': 256, 'ellipse_count': 10, 'ellipse_size': 50, 'ellipse_size_min': 10, 'blurred': False}, 'out_dir': './LearnedRadonFilters', 'deterministic': True, 'seed': 1234567, 'device': 'cuda', 'num_workers': 1, 'checkpoint': None, 'validation_split_percent': 20, 'training_batch_size': 32, 'shuffle_training_data': True, 'drop_last_training_batch': False, 'validation_batch_size': '${training_batch_size}', 'shuffle_validation_data': False, 'drop_last_validation_batch': False, 'test_batch_size': '${training_batch_size}', 'shuffle_test_data': False, 'drop_last_test_batch': True, 'sino_angles': None, 'sino_positions': None, 'noise_level': 1.0, 'optimizer_lr': 0.001, 'epochs': 3, 'training_batch_count': -1, 'validation_batch_count': -1, 'test_batch_count': -1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd0d0dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "32\n",
      "256\n",
      "50\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(config.training_batch_count     )\n",
    "print(config.training_batch_size      )\n",
    "print(config.dataset.img_size         )\n",
    "print(config.dataset.ellipse_size     )\n",
    "print(config.dataset.ellipse_size_min )\n",
    "print(config.dataset.ellipse_count    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "021384c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.training_batch_count     = -1 #2    #-1\n",
    "config.training_batch_size      = 1 # 32 #1    #32\n",
    "config.dataset.img_size         = 64 #256 #256\n",
    "config.dataset.ellipse_size     = 20 #5 #50\n",
    "config.dataset.ellipse_size_min = 20 #5 #10 #if size_min is larger than size, the size is deterministic\n",
    "config.dataset.ellipse_count    = 1 #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "358cca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(config.dataset.blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b9132154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_transform = None\n",
    "test_transform = T.Compose([\n",
    "    T.Lambda(lambda x: T.Resize(size=64)(x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_imgs = [T.Resize(size=size)(X[0][0]) for size in (10, 20, 30, 64)]\n",
    "\n",
    "resized_imgs_64x64 = []\n",
    "for img in resized_imgs:\n",
    "    resized_imgs_64x64.append(T.Resize(size=64)(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2da17dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "del training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fb6a197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = _EllipsesDataset((640 if config.training_batch_count == -1 else config.training_batch_count)*config.training_batch_size, config.dataset.img_size, config.dataset.ellipse_count, config.dataset.ellipse_size, config.dataset.ellipse_size_min, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce03dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for newX in training_dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8157e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newX[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024701a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3a07bcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EllipsesDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, config: omegaconf.DictConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def train_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        training_transform = torchvision.transforms.Compose([\n",
    "            #torchvision.transforms.Lambda(lambda x: torchvision.transforms.functional.gaussian_blur(x, 5, 2.5))\n",
    "            #torchvision.transforms.Lambda(lambda x: torchvision.transforms.Resize(size=64)(x))\n",
    "            torchvision.transforms.Resize(size=[64,64])\n",
    "        ])\n",
    "        training_dataset = _EllipsesDataset((640 if self.config.training_batch_count == -1 else self.config.training_batch_count)*self.config.training_batch_size, self.config.dataset.img_size, self.config.dataset.ellipse_count, self.config.dataset.ellipse_size, self.config.dataset.ellipse_size_min, training_transform if self.config.dataset.blurred else None)\n",
    "        return torch.utils.data.DataLoader(training_dataset, drop_last=self.config.drop_last_training_batch, batch_size=self.config.training_batch_size, shuffle=self.config.shuffle_training_data, num_workers=self.config.num_workers)\n",
    "    \n",
    "    def val_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        validation_transform = torchvision.transforms.Compose([\n",
    "            #torchvision.transforms.Lambda(lambda x: torchvision.transforms.functional.gaussian_blur(x, 5, 2.5))\n",
    "            #torchvision.transforms.Lambda(lambda x: torchvision.transforms.Resize(size=64)(x))\n",
    "            torchvision.transforms.Resize(size=64)\n",
    "        ])\n",
    "        validation_dataset = _EllipsesDataset((160 if self.config.validation_batch_count == -1 else self.config.validation_batch_count)*self.config.validation_batch_size, self.config.dataset.img_size, self.config.dataset.ellipse_count, self.config.dataset.ellipse_size, self.config.dataset.ellipse_size_min, validation_transform if self.config.dataset.blurred else None)\n",
    "        return torch.utils.data.DataLoader(validation_dataset, drop_last=self.config.drop_last_validation_batch, batch_size=self.config.validation_batch_size, shuffle=self.config.shuffle_validation_data, num_workers=self.config.num_workers)\n",
    "\n",
    "    def test_dataloader(self) -> torch.utils.data.DataLoader:\n",
    "        test_transform = torchvision.transforms.Compose([\n",
    "            #torchvision.transforms.Lambda(lambda x: torchvision.transforms.functional.gaussian_blur(x, 5, 2.5))\n",
    "            #torchvision.transforms.Lambda(lambda x: torchvision.transforms.Resize(size=64)(x))\n",
    "            torchvision.transforms.Resize(size=64)\n",
    "        ])\n",
    "        test_dataset = _EllipsesDataset((200 if self.config.test_batch_count == -1 else self.config.test_batch_count)*self.config.test_batch_size, self.config.dataset.img_size, self.config.dataset.ellipse_count, self.config.dataset.ellipse_size, self.config.dataset.ellipse_size_min, test_transform if self.config.dataset.blurred else None)\n",
    "        return torch.utils.data.DataLoader(test_dataset, drop_last=self.config.drop_last_test_batch, batch_size=self.config.test_batch_size, shuffle=self.config.shuffle_test_data, num_workers=self.config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9aa5a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.dataset.blurred = True\n",
    "\n",
    "datamodule = EllipsesDataModule(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1093cd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.EllipsesDataModule at 0x13c636dc8b0>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a755d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=datamodule.train_dataloader(),\n",
    "batch_size=1,\n",
    "shuffle=True,\n",
    "num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fa50ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader = datamodule.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4126db86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datamodule.train_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "01c01cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x13c63b58190>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9973521a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _SingleProcessDataLoaderIter._next_data of <torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x0000013C63CB85E0>>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for batch_ndx, sample in enumerate(train_loader):\n",
    "#    break\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "data_iter._next_data\n",
    "#data = data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "63ed2e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ab4a6b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "afde8350",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [188], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m x:\n\u001b[0;32m      2\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for img in x:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c9ec2bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 64, 64])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2318a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bc3f0359",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\danil\\Desktop\\oct2022\\test\\ellipses_datamodule.py\", line 58, in __getitem__\n    if self.ellipse_angle[idx] == 0.0:\nIndexError: index 20451 is out of bounds for dimension 0 with size 20400\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [126], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m(trainloader):\n\u001b[0;32m      2\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1376\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1375\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1376\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1402\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   1401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1402\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   1403\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> 461\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\danil\\Desktop\\oct2022\\py396_2022\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"c:\\Users\\danil\\Desktop\\oct2022\\test\\ellipses_datamodule.py\", line 58, in __getitem__\n    if self.ellipse_angle[idx] == 0.0:\nIndexError: index 20451 is out of bounds for dimension 0 with size 20400\n"
     ]
    }
   ],
   "source": [
    "for x in iter(trainloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "09a7ab4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [125], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de64ce59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a18375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb4b773a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__._EllipsesDataset at 0x13c548cdf10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e147777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_imgs = [T.Resize(size=size)(X[0][0]) for size in (10, 20, 30, 64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6420788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_img = X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11a115c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(imgs, with_orig=True, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, squeeze=False)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        row = [orig_img] + row if with_orig else row\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Original image')\n",
    "        axs[0, 0].title.set_size(8)\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"my_resized.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f97f1f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m resized_imgs \u001b[39m=\u001b[39m [T\u001b[39m.\u001b[39mResize(size\u001b[39m=\u001b[39msize)(X[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m size \u001b[39min\u001b[39;00m (\u001b[39m10\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m30\u001b[39m, \u001b[39m64\u001b[39m)]\n\u001b[0;32m      3\u001b[0m resized_imgs_64x64 \u001b[39m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m resized_imgs:\n",
      "Cell \u001b[1;32mIn [41], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m resized_imgs \u001b[39m=\u001b[39m [T\u001b[39m.\u001b[39mResize(size\u001b[39m=\u001b[39msize)(X[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m size \u001b[39min\u001b[39;00m (\u001b[39m10\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m30\u001b[39m, \u001b[39m64\u001b[39m)]\n\u001b[0;32m      3\u001b[0m resized_imgs_64x64 \u001b[39m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m resized_imgs:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "resized_imgs = [T.Resize(size=size)(X[0][0]) for size in (10, 20, 30, 64)]\n",
    "\n",
    "resized_imgs_64x64 = []\n",
    "for img in resized_imgs:\n",
    "    resized_imgs_64x64.append(T.Resize(size=64)(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fa3dadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([30, 30])\n",
      "torch.Size([64, 64])\n"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=4, squeeze=False)\n",
    "\n",
    "for cont, x in enumerate (resized_imgs):\n",
    "    print(x[0].shape)\n",
    "    ax = axs[0,cont]\n",
    "    ax.imshow(x[0])\n",
    "    \n",
    "fig.savefig(f\"my_resized.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ccbe45b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=4, squeeze=False)\n",
    "\n",
    "for cont, x in enumerate (resized_imgs_64x64):\n",
    "    print(x[0].shape)\n",
    "    ax = axs[0,cont]\n",
    "    ax.imshow(x[0])\n",
    "    \n",
    "fig.savefig(f\"my_resized_64x64.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55559832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce3a45d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 10])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resized_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81dad968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.full((my_img_count,), my_ellipses_count).to(torch.float32)).to(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf0615a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 0, 0, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.poisson(torch.full((my_img_count,), my_ellipses_count).to(torch.float32)).to(torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b0930bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newX[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "25913f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = T.Compose([\n",
    "    T.Lambda(lambda x: T.Resize(size=5)(x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d2d559b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 5])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transform(newX[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "431ac448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transform(newX[0]).shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c019f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transform(newX[0]).view(test_transform(newX[0]).shape[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a6647d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cont, newX in enumerate(training_dataset):\n",
    "    plt.imshow(test_transform(newX[0]).view(test_transform(newX[0]).shape[-2:]))\n",
    "    plt.savefig(f\"my_resized_one_ellipse_noPoisson__{cont:03}__10x10.png\")\n",
    "    if cont>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf780cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(newX[0].shape)\n",
    "\n",
    "cont = 1\n",
    "for newX in training_dataset:\n",
    "    plt.imshow((newX[0]).view(config.dataset.img_size,config.dataset.img_size))\n",
    "    plt.savefig(f\"my_ten_ellipse_noPoisson__{cont:03}.png\")\n",
    "    cont+=1\n",
    "    if cont>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95fb2de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b99d5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(X[0][0].view(256,256)[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5fddaf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((X[0][31]).view(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81024b29",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EllipsesDataModule' object has no attribute 'training_batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m config\u001b[39m.\u001b[39;49mtraining_batch_size\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'EllipsesDataModule' object has no attribute 'training_batch_size'"
     ]
    }
   ],
   "source": [
    "config.training_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute training and testing\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", r\"Checkpoint directory .+ exists and is not empty\\.\") #Needed thanks to the custom logger\n",
    "    warnings.filterwarnings(\"ignore\", r\"The dataloader, ((train)|(val)|(test)) dataloader( \\d+)?, does not have many workers which may be a bottleneck\\. Consider increasing the value of the `num_workers` argument` \\(try \\d+ which is the number of cpus on this machine\\) in the `DataLoader` init to improve performance\\.\") #BUG Contradictory warnings with num_workers on cluster and slow loading with LoDoPaB\n",
    "    trainer = pytorch_lightning.Trainer(\n",
    "        deterministic=config.deterministic, \n",
    "        callbacks=[pytorch_lightning.callbacks.ModelCheckpoint(dirpath=\".\")], \n",
    "        accelerator=\"gpu\" if config.device == \"cuda\" else None, \n",
    "        max_epochs=config.epochs, \n",
    "        logger=CustomTensorBoardLogger(hydra.core.hydra_config.HydraConfig.get().runtime.output_dir, None, \"\"), \n",
    "        limit_train_batches=int(config.training_batch_count) if config.training_batch_count != -1 else len(datamodule.train_dataloader()), \n",
    "        limit_val_batches=int(config.validation_batch_count) if config.validation_batch_count != -1 else len(datamodule.val_dataloader()), \n",
    "        limit_test_batches=int(config.test_batch_count) if config.test_batch_count != -1 else len(datamodule.test_dataloader()))\n",
    "    trainer.fit(model, datamodule)\n",
    "    trainer.test(model, datamodule)\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").handlers.remove(logger.root.handlers[1]) #Stops pytorch lightning from writing to previous runs during multiruns\n",
    "\n",
    "\n",
    "this_dir = os.getcwd()\n",
    "print(this_dir)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('py396_2022': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "728da063adee70d344dc69477bf203d2b79ed062e98e9ab3ec51282dd2dfe849"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
